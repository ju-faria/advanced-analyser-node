<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Demo 1</title>
</head>
<body>
  <canvas></canvas>
  <br />
  <button>get float frequency data</button>
  <button>draw byte frequency data</button>
  <button>get float time domain data</button>
  <button>draw byte time domain data</button>
  <br />

  <canvas></canvas>
  <pre></pre>
</body>
<script src="../dist/bundle.js"></script>
<script>
  (async () => {
    const FFT_SIZE = 1024 * 2
    const SAMPLE_RATE = 44100

    const [canvas, snapshotCanvas] = document.querySelectorAll('canvas')
    const context2d =  canvas.getContext('2d')
    const snapshotContext2d =  snapshotCanvas.getContext('2d')
    const output = document.querySelector('pre')

    const [floatFrequencyButton, byteFrequencyButton, floatTimeDomainButton, byteTimeDomainButton] = document.querySelectorAll('button')

    const stream = await  navigator.mediaDevices.getUserMedia({
      audio: true,
      video: false
    })
    
    canvas.height = 300
    canvas.width = 1024
    

    snapshotCanvas.height = 300
    snapshotCanvas.width = 1024
    
    const context = new AudioContext({ sampleRate: SAMPLE_RATE })
    
    const audioSource = context.createMediaStreamSource(stream);

    const bottomMargin = 30
    const analyserNode = await advancedAnalyserNode.createAdvancedAnalyserNode(context, {
      fftSize: FFT_SIZE,
      samplesBetweenTransforms: FFT_SIZE,
      windowFunction: 'none'
    })
    
    const drawFrame = (canvas, context2d, data) => {
      context2d.clearRect(0, 0, canvas.width, canvas.height)
      context2d.beginPath()
      for(let i = 0; i < data.length; i ++) {
        if (i === 0) {
          context2d.moveTo(canvas.width / data.length * i, canvas.height -  bottomMargin - data[i] ) 
        } else {
          context2d.lineTo(canvas.width / data.length * i, canvas.height -  bottomMargin - data[i] ) 
        }
      }
      context2d.stroke()
    }
    analyserNode.addEventListener('bytefrequencydata', ({ detail }) => {
      drawFrame(canvas, context2d, detail)
    })
    audioSource.connect(analyserNode)

    floatFrequencyButton.onclick = async () => {
      const response = await analyserNode.getFloatFrequencyData()

      output.innerHTML = 
      `
        \nFloat Frequency Data

        \nSize: ${response.length}
        \n${response.toString().replace(/,/g, '\n')}
      `
    }

    byteFrequencyButton.onclick = async () => {
      const response = await analyserNode.getByteFrequencyData()
      drawFrame(snapshotCanvas, snapshotContext2d, response)
      output.innerHTML = 
      `
        \nByte Frequency Data

        \nSize: ${response.length}
        \n${response.toString().replace(/,/g, '\n')}
      `
    }

    floatTimeDomainButton.onclick = async () => {
      const response = await analyserNode.getFloatTimeDomainData()

      output.innerHTML = 
      `
        \nFloat Time Domain Data

        \nSize: ${response.length}
        \n${response.toString().replace(/,/g, '\n')}
      `
    }

    byteTimeDomainButton.onclick = async () => {
      const response = await analyserNode.getByteTimeDomainData()
      drawFrame(snapshotCanvas, snapshotContext2d, response)
      output.innerHTML = 
      `
        \nByte Time Domain Data

        \nSize: ${response.length}
        \n${response.toString().replace(/,/g, '\n')}
      `
    }

    
  })()
</script>
</html>